from ...extras.packages import is_gradio_available
if is_gradio_available():
    import gradio as gr
from ...extras.constants import SUPPORTED_MODEL
from ...handler.train import get_train_config

def build_train_config_tab(tabs: gr.Tabs, status_indicator: gr.HTML) -> None:
    with gr.Column():
        gr.Markdown("### è®­ç»ƒä»»åŠ¡é…ç½®")
        with gr.Row():
            model_id = gr.Dropdown(
                choices=SUPPORTED_MODEL,
                label="æ¨¡åž‹é€‰æ‹©",
                value=SUPPORTED_MODEL[0],
                interactive=True
            )
            mode = gr.Dropdown(
                choices=["pretrain", "SFT(å…¨å‚)", "SFT(LoRA)"],
                value="pretrain",
                interactive=True
            )
            npus = gr.Number(label="æ¯èŠ‚ç‚¹npuå¡æ•°", value=8, precision=0, interactive=True)
        with gr.Row():
            master_addr = gr.Textbox(
                label="èŠ‚ç‚¹ip",
                info="å•æœºä½¿ç”¨æœ¬èŠ‚ç‚¹ip,å¤šæœºæ‰€æœ‰èŠ‚ç‚¹éƒ½é…ç½®ä¸ºmaster_ip",
                value="localhost",
                interactive=True
            )
            master_port = gr.Number(label="ç«¯å£å·", value=6000, precision=0, interactive=True)
            nodes = gr.Number(label="èŠ‚ç‚¹æ•°é‡", value=1, precision=0, interactive=True)
        with gr.Row():
            load_dir = gr.Textbox(
                label="æ¨¡åž‹è½¬æ¢åŽæƒé‡è·¯å¾„",
                value="./models_mcore_weights/your_model/",
                interactive=True
            )
            save_dir = gr.Textbox(
                label="æ¨¡åž‹è®­ç»ƒåŽæƒé‡ä¿å­˜è·¯å¾„",
                value="./ckpt/your_model",
                interactive=True
            )
        with gr.Row():
            data_path = gr.Textbox(
                label="æ•°æ®é›†è½¬æ¢åŽè·¯å¾„",
                value="./dataset/dst/your_dataset_text_document",
                interactive=True
            )
            tokenizer_path = gr.Textbox(
                label="æ•°æ®é›†è½¬æ¢åŽè·¯å¾„",
                value="./models_from_hf/your_model/",
                interactive=True
            )
        md = gr.Markdown("> ðŸ’¡ æç¤º:æ­¤å¤„å¹¶è¡Œè®¾ç½®åº”ä¸Ž**æ¨¡åž‹æƒé‡è½¬æ¢**æ—¶è®¾ç½®ä¿æŒä¸€è‡´")
        with gr.Row():
            tp = gr.Number(label="tensor-parallel-size", value=1, precision=0, interactive=True)
            pp = gr.Number(label="pipeline-parallel-size", value=4, precision=0, interactive=True)
            cp = gr.Number(label="context-parallel-size", value=1, precision=0, interactive=True)
            seq_len = gr.Number(label="seq_length", value=4096, precision=0, interactive=True)
            mbs = gr.Number(label="micro-batch-size", info="å¾®æ‰¹æ¬¡å¤§å°,å†³å®šæ¯æ¬¡å‰å‘/åå‘ä¼ æ’­å¤„ç†çš„æ ·æœ¬æ•°é‡ã€‚è¾ƒå¤§çš„å€¼å¯ä»¥æé«˜GPUåˆ©ç”¨çŽ‡,ä½†ä¼šå¢žåŠ å†…å­˜ä½¿ç”¨", value=1, precision=0, interactive=True)
            gbs = gr.Number(label="global-batch-size", info="å…¨å±€æ‰¹æ¬¡å¤§å°,æ˜¯ä¸€æ¬¡è¿­ä»£æ›´æ–°çš„æ€»æ ·æœ¬æ•°", value=64, precision=0, interactive=True)
        # def update_parallel_visibility(model_id: str) -> list[gr.Number, gr.Number, gr.Number, gr.Markdown]:
        #     tp_visible = model_id in TP_SUPPORTED_MODEL
        #     pp_visible = model_id in PP_SUPPORTED_MODEL
        #     cp_visible = model_id in CP_SUPPORTED_MODEL
        #     return [
        #         gr.update(visible=tp_visible),
        #         gr.update(visible=pp_visible),
        #         gr.update(visible=cp_visible),
        #         gr.update(visible=tp_visible or pp_visible or cp_visible)
        #     ]
        
        # model_id.change(
        #     fn=update_parallel_visibility,
        #     inputs=[model_id],
        #     outputs=[tp, pp, cp, md]
        # )
        with gr.Row():
            epochs = gr.Number(label="epochs", value=1, precision=0, interactive=True)
            lr = gr.Number(label="å­¦ä¹ çŽ‡", value=0.001, interactive=True)
        train_btn = gr.Button("å¼€å§‹è®­ç»ƒ")
        train_btn.click(
            fn=get_train_config,
            inputs=[model_id, mode, npus, master_addr, master_port, nodes, load_dir, save_dir, data_path, tokenizer_path, tp, pp , cp, seq_len, mbs, gbs, epochs, lr],
            outputs=[tabs, status_indicator]
        )